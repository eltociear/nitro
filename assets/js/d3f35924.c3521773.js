"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1982],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),p=u(n),m=r,h=p["".concat(s,".").concat(m)]||p[m]||d[m]||l;return n?a.createElement(h,o(o({ref:t},c),{},{components:n})):a.createElement(h,o({ref:t},c))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,o=new Array(l);o[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[p]="string"==typeof e?e:r,o[1]=i;for(var u=2;u<l;u++)o[u]=n[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},43071:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>d,frontMatter:()=>l,metadata:()=>i,toc:()=>u});var a=n(87462),r=(n(67294),n(3905));const l={title:"Quickstart"},o=void 0,i={unversionedId:"new/quickstart",id:"new/quickstart",title:"Quickstart",description:"Step 1: Install Nitro",source:"@site/docs/new/quickstart.md",sourceDirName:"new",slug:"/new/quickstart",permalink:"/new/quickstart",draft:!1,editUrl:"https://github.com/janhq/nitro/tree/main/docs/docs/new/quickstart.md",tags:[],version:"current",lastUpdatedBy:"automaticcat",lastUpdatedAt:1700543200,formattedLastUpdatedAt:"Nov 21, 2023",frontMatter:{title:"Quickstart"},sidebar:"docsSidebar",previous:{title:"About Nitro",permalink:"/docs"},next:{title:"Installation",permalink:"/install"}},s={},u=[{value:"Step 1: Install Nitro",id:"step-1-install-nitro",level:2},{value:"For Linux and MacOS",id:"for-linux-and-macos",level:3},{value:"For Windows",id:"for-windows",level:3},{value:"Step 2: Downloading a Model",id:"step-2-downloading-a-model",level:2},{value:"Step 3: Run Nitro server",id:"step-3-run-nitro-server",level:2},{value:"Step 4: Load model",id:"step-4-load-model",level:2},{value:"Step 5: Making an Inference",id:"step-5-making-an-inference",level:2}],c={toc:u},p="wrapper";function d(e){let{components:t,...n}=e;return(0,r.kt)(p,(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"step-1-install-nitro"},"Step 1: Install Nitro"),(0,r.kt)("h3",{id:"for-linux-and-macos"},"For Linux and MacOS"),(0,r.kt)("p",null,"Open your terminal and enter the following command. This will download and install Nitro on your system."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl -sfL https://raw.githubusercontent.com/janhq/nitro/main/install.sh -o /tmp/install.sh && chmod +x /tmp/install.sh && sudo bash /tmp/install.sh --gpu && rm /tmp/install.sh\n")),(0,r.kt)("h3",{id:"for-windows"},"For Windows"),(0,r.kt)("p",null,"Open PowerShell and execute the following command. This will perform the same actions as for Linux and MacOS but is tailored for Windows."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"powershell -Command \"& { Invoke-WebRequest -Uri 'https://raw.githubusercontent.com/janhq/nitro/main/install.bat' -OutFile 'install.bat'; .\\install.bat --gpu; Remove-Item -Path 'install.bat' }\"\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"NOTE:"),"Installing Nitro will add new files and configurations to your system to enable it to run.")),(0,r.kt)("p",null,"For a manual installation process, see: ",(0,r.kt)("a",{parentName:"p",href:"/install"},"Install from Source")),(0,r.kt)("h2",{id:"step-2-downloading-a-model"},"Step 2: Downloading a Model"),(0,r.kt)("p",null,"Next, we need to download a model. For this example, we'll use the ",(0,r.kt)("a",{parentName:"p",href:"https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main"},"Llama2 7B chat model"),"."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Create a ",(0,r.kt)("inlineCode",{parentName:"li"},"/model")," and navigate into it:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir model && cd model\nwget -O llama-2-7b-model.gguf https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_K_M.gguf?download=true\n")),(0,r.kt)("h2",{id:"step-3-run-nitro-server"},"Step 3: Run Nitro server"),(0,r.kt)("p",null,"To start using Nitro, you need to run its server."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="Run Nitro server"',title:'"Run',Nitro:!0,'server"':!0},"nitro\n")),(0,r.kt)("p",null,"To check if the Nitro server is running:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="Nitro Health Status"',title:'"Nitro',Health:!0,'Status"':!0},"curl http://localhost:3928/healthz\n")),(0,r.kt)("h2",{id:"step-4-load-model"},"Step 4: Load model"),(0,r.kt)("p",null,"To load the model to Nitro server, you need to run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="Load model"',title:'"Load','model"':!0},'curl http://localhost:3928/inferences/llamacpp/loadmodel \\\n  -H \'Content-Type: application/json\' \\\n  -d \'{\n    "llama_model_path": "/model/llama-2-7b-model.gguf",\n    "ctx_len": 512,\n    "ngl": 100,\n  }\'\n')),(0,r.kt)("h2",{id:"step-5-making-an-inference"},"Step 5: Making an Inference"),(0,r.kt)("p",null,"Finally, let's make an actual inference call using Nitro."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"In your terminal, execute:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="Nitro Inference"',title:'"Nitro','Inference"':!0},'curl http://localhost:3928/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "messages": [\n      {\n        "role": "user",\n        "content": "Who won the world series in 2020?"\n      },\n    ]\n  }\'\n')),(0,r.kt)("p",null,"This command sends a request to Nitro, asking it about the 2020 World Series winner."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"As you can see, A key benefit of Nitro is its alignment with ",(0,r.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/guides/text-generation?lang=curl"},"OpenAI's API structure"),". Its inference call syntax closely mirrors that of OpenAI's API, facilitating an easier shift for those accustomed to OpenAI's framework.")))}d.isMDXComponent=!0}}]);