"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9701],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var i=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=i.createContext({}),p=function(e){var t=i.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=p(e.components);return i.createElement(s.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},d=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=p(n),d=a,h=c["".concat(s,".").concat(d)]||c[d]||m[d]||r;return n?i.createElement(h,o(o({ref:t},u),{},{components:n})):i.createElement(h,o({ref:t},u))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,o=new Array(r);o[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[c]="string"==typeof e?e:a,o[1]=l;for(var p=2;p<r;p++)o[p]=n[p];return i.createElement.apply(null,o)}return i.createElement.apply(null,n)}d.displayName="MDXCreateElement"},89217:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var i=n(87462),a=(n(67294),n(3905));const r={title:"About Nitro",slug:"/docs"},o=void 0,l={unversionedId:"new/about",id:"new/about",title:"About Nitro",description:"Nitro is a high-efficiency C++ inference engine for edge computing, powering Jan. It is lightweight and embeddable, ideal for product integration.",source:"@site/docs/new/about.md",sourceDirName:"new",slug:"/docs",permalink:"/docs",draft:!1,editUrl:"https://github.com/janhq/nitro/tree/main/docs/docs/new/about.md",tags:[],version:"current",lastUpdatedBy:"automaticcat",lastUpdatedAt:1700715299,formattedLastUpdatedAt:"Nov 23, 2023",frontMatter:{title:"About Nitro",slug:"/docs"},sidebar:"docsSidebar",next:{title:"Quickstart",permalink:"/quickstart"}},s={},p=[{value:"Why Nitro?",id:"why-nitro",level:2},{value:"OpenAI-compatible API",id:"openai-compatible-api",level:3},{value:"Cross-Platform",id:"cross-platform",level:3},{value:"Multi-modal Capabilities",id:"multi-modal-capabilities",level:3},{value:"Architecture",id:"architecture",level:2},{value:"Support",id:"support",level:2},{value:"GitHub Issue Tracking",id:"github-issue-tracking",level:3},{value:"Discord Community",id:"discord-community",level:3},{value:"Contributing",id:"contributing",level:2},{value:"How to Contribute",id:"how-to-contribute",level:3},{value:"Links",id:"links",level:3},{value:"Acknowledgements",id:"acknowledgements",level:2}],u={toc:p},c="wrapper";function m(e){let{components:t,...n}=e;return(0,a.kt)(c,(0,i.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Nitro is a high-efficiency C++ inference engine for edge computing, powering ",(0,a.kt)("a",{parentName:"p",href:"https://jan.ai/"},"Jan"),". It is lightweight and embeddable, ideal for product integration."),(0,a.kt)("p",null,"Learn more on ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/janhq/nitro"},"GitHub"),"."),(0,a.kt)("h2",{id:"why-nitro"},"Why Nitro?"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Fast Inference:")," Built on top of the cutting-edge inference library ",(0,a.kt)("inlineCode",{parentName:"li"},"llama.cpp"),", modified to be production ready."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Lightweight:")," Only 3MB, ideal for resource-sensitive environments."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Easily Embeddable:")," Simple integration into existing applications, offering flexibility."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Quick Setup:")," Approximately 10-second initialization for swift deployment."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Enhanced Web Framework:")," Incorporates ",(0,a.kt)("inlineCode",{parentName:"li"},"drogon cpp")," to boost web service efficiency.")),(0,a.kt)("h3",{id:"openai-compatible-api"},"OpenAI-compatible API"),(0,a.kt)("p",null,"One of the significant advantages of using Nitro is its compatibility with OpenAI's API structure. The command format for making inference calls with Nitro is very similar to that used with OpenAI's API. This similarity ensures a transition for users who are already familiar with OpenAI's system."),(0,a.kt)("p",null,"For instance, compare the Nitro inference call:"),(0,a.kt)("div",{style:{width:"50%",float:"left",clear:"left"}},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="Nitro chat completion"',title:'"Nitro',chat:!0,'completion"':!0},'curl http://localhost:3928/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "gpt-3.5-turbo",\n    "messages": [\n      {\n        "role": "system",\n        "content": "You are a helpful assistant."\n      },\n      {\n        "role": "user",\n        "content": "Who won the world series in 2020?"\n      },\n    ]\n  }\'\n\n'))),(0,a.kt)("div",{style:{width:"50%",float:"right",clear:"right"}},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="OpenAI API chat completion"',title:'"OpenAI',API:!0,chat:!0,'completion"':!0},'curl https://api.openai.com/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer $OPENAI_API_KEY" \\\n  -d \'{\n    "model": "gpt-3.5-turbo",\n    "messages": [\n      {\n        "role": "system",\n        "content": "You are a helpful assistant."\n      },\n      {\n        "role": "user",\n        "content": "Who won the world series in 2020?"\n      },\n    ]\n  }\'\n'))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Extends OpenAI's API with helpful model methods:"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"features/load-unload#unload-model"},"Unload model")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"features/load-unload/#status"},"Checking model status"))))),(0,a.kt)("h3",{id:"cross-platform"},"Cross-Platform"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Operating Systems"),": Nitro Supports Windows, Linux, and MacOS."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Hardware Compatibility"),":",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"CPUs: ARM, x86."),(0,a.kt)("li",{parentName:"ul"},"GPUs: Nvidia, AMD."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Detailed Resources"),": ",(0,a.kt)("a",{parentName:"li",href:"install/#windows"},"Windows Installation Guide"),", ",(0,a.kt)("a",{parentName:"li",href:"install/#linux-and-macos"},"Linux and MacOS Installation Guide"),".")),(0,a.kt)("h3",{id:"multi-modal-capabilities"},"Multi-modal Capabilities"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Coming Soon"),": Expansion to multi-modal functionalities - enabling Nitro to process and generate images, and audio."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Features to Expect"),":",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Large Language-and-Vision Assistant."),(0,a.kt)("li",{parentName:"ul"},"Speech recognition and transcription.")))),(0,a.kt)("h2",{id:"architecture"},"Architecture"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Overview"),": Nitro's architecture is designed for scalability and efficiency, utilizing a modular framework that supports diverse AI functionalities."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Detailed Specifications"),": For an in-depth understanding of Nitro's internal workings, components, and design philosophy, refer to our ",(0,a.kt)("a",{parentName:"li",href:"/achitecture"},"Architecture Specifications"),".")),(0,a.kt)("h2",{id:"support"},"Support"),(0,a.kt)("h3",{id:"github-issue-tracking"},"GitHub Issue Tracking"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Report Problems"),": Encounter an issue with Nitro? File a ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/janhq/nitro"},"GitHub issue"),". Please include detailed error logs and steps to reproduce the problem.")),(0,a.kt)("h3",{id:"discord-community"},"Discord Community"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Join the Conversation"),": Discuss Nitro development and seek peer support in our ",(0,a.kt)("a",{parentName:"li",href:"https://discord.gg/FTk2MvZwJH"},"#nitro-dev")," channel on Discord.")),(0,a.kt)("h2",{id:"contributing"},"Contributing"),(0,a.kt)("h3",{id:"how-to-contribute"},"How to Contribute"),(0,a.kt)("p",null,"Nitro welcomes contributions in various forms, not just coding. Here are some ways you can get involved:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Understand Nitro"),": Start with the ",(0,a.kt)("a",{parentName:"p",href:"/new/quickstart"},"Getting Started")," guide. Found an issue or have a suggestion? ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/janhq/nitro/issues"},"Open an issue")," to let us know.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Feature Development"),": Engage with community feature requests. Bring ideas to life by opening a ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/janhq/nitro/pulls"},"pull request")," for features that interest you."))),(0,a.kt)("h3",{id:"links"},"Links"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/janhq/nitro"},"Nitro GitHub Repository"))),(0,a.kt)("h2",{id:"acknowledgements"},"Acknowledgements"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/drogonframework/drogon"},"drogon"),": The fast C++ web framework"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/ggerganov/llama.cpp"},"llama.cpp"),": Inference of LLaMA model in pure C/C++")))}m.isMDXComponent=!0}}]);