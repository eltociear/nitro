"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4785],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>h});var o=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var p=o.createContext({}),s=function(e){var n=o.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=s(e.components);return o.createElement(p.Provider,{value:n},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},m=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=s(t),m=a,h=d["".concat(p,".").concat(m)]||d[m]||u[m]||r;return t?o.createElement(h,i(i({ref:n},c),{},{components:t})):o.createElement(h,i({ref:n},c))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,i=new Array(r);i[0]=m;var l={};for(var p in n)hasOwnProperty.call(n,p)&&(l[p]=n[p]);l.originalType=e,l[d]="string"==typeof e?e:a,i[1]=l;for(var s=2;s<r;s++)i[s]=t[s];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}m.displayName="MDXCreateElement"},95129:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>s});var o=t(87462),a=(t(67294),t(3905));const r={title:"Nitro with openai-node"},i=void 0,l={unversionedId:"examples/openai-node",id:"examples/openai-node",title:"Nitro with openai-node",description:"You can migrate from OAI API or Azure OpenAI to Nitro using your existing NodeJS code quickly",source:"@site/docs/examples/openai-node.md",sourceDirName:"examples",slug:"/examples/openai-node",permalink:"/examples/openai-node",draft:!1,editUrl:"https://github.com/janhq/nitro/tree/main/docs/docs/examples/openai-node.md",tags:[],version:"current",lastUpdatedBy:"automaticcat",lastUpdatedAt:1700704289,formattedLastUpdatedAt:"Nov 23, 2023",frontMatter:{title:"Nitro with openai-node"},sidebar:"docsSidebar",previous:{title:"Nitro with Chatbox",permalink:"/examples/chatbox"},next:{title:"Nitro with openai-python",permalink:"/examples/openai-python"}},p={},s=[{value:"Chat Completion",id:"chat-completion",level:2},{value:"Embedding",id:"embedding",level:2},{value:"Audio",id:"audio",level:2},{value:"How to reproduce",id:"how-to-reproduce",level:2}],c={toc:s},d="wrapper";function u(e){let{components:n,...t}=e;return(0,a.kt)(d,(0,o.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"You can migrate from OAI API or Azure OpenAI to Nitro using your existing NodeJS code quickly"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The ONLY thing you need to do is to override ",(0,a.kt)("inlineCode",{parentName:"p"},"baseURL")," in ",(0,a.kt)("inlineCode",{parentName:"p"},"openai")," init with ",(0,a.kt)("inlineCode",{parentName:"p"},"Nitro")," URL"),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},"NodeJS OpenAI SDK: ",(0,a.kt)("a",{parentName:"li",href:"https://www.npmjs.com/package/openai"},"https://www.npmjs.com/package/openai")))),(0,a.kt)("h2",{id:"chat-completion"},"Chat Completion"),(0,a.kt)("table",null,(0,a.kt)("tr",null,(0,a.kt)("td",null," Engine ")," ",(0,a.kt)("td",null," Typescript Code ")),(0,a.kt)("tr",null,(0,a.kt)("td",null," Nitro "),(0,a.kt)("td",null,(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-typescript"},"import OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: '', // defaults to process.env[\"OPENAI_API_KEY\"]\n  baseURL: \"http://localhost:3928/v1/\" // https://api.openai.com/v1\n});\n\nasync function chatCompletion() {\n  const stream = await openai.beta.chat.completions.stream({\n    model: 'gpt-3.5-turbo',\n    messages: [{ role: 'user', content: 'Say this is a test' }],\n    stream: true,\n  });\n\n  stream.on('content', (delta, snapshot) => {\n    process.stdout.write(delta);\n  });\n\n  for await (const chunk of stream) {\n    process.stdout.write(chunk.choices[0]?.delta?.content || '');\n  }\n\n  const chatCompletion = await stream.finalChatCompletion();\n  console.log(chatCompletion); // {id: \"\u2026\", choices: [\u2026], \u2026}\n}\nchatCompletion()\n")))),(0,a.kt)("tr",null,(0,a.kt)("td",null," OAI "),(0,a.kt)("td",null,(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-typescript"},"import OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: '', // defaults to process.env[\"OPENAI_API_KEY\"]\n});\n\nasync function chatCompletion() {\n  const stream = await openai.beta.chat.completions.stream({\n    model: 'gpt-3.5-turbo',\n    messages: [{ role: 'user', content: 'Say this is a test' }],\n    stream: true,\n  });\n\n  stream.on('content', (delta, snapshot) => {\n    process.stdout.write(delta);\n  });\n\n  for await (const chunk of stream) {\n    process.stdout.write(chunk.choices[0]?.delta?.content || '');\n  }\n\n  const chatCompletion = await stream.finalChatCompletion();\n  console.log(chatCompletion); // {id: \"\u2026\", choices: [\u2026], \u2026}\n}\nchatCompletion()\n")))),(0,a.kt)("tr",null,(0,a.kt)("td",null," Azure OAI "),(0,a.kt)("td",null,(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-typescript"},"import OpenAI from 'openai';\n// The name of your Azure OpenAI Resource.\n// https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\nconst resource = '<your resource name>';\n\n// Corresponds to your Model deployment within your OpenAI resource, e.g. my-gpt35-16k-deployment\n// Navigate to the Azure OpenAI Studio to deploy a model.\nconst model = '<your model>';\n\n// https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\nconst apiVersion = '2023-06-01-preview';\n\nconst apiKey = process.env['AZURE_OPENAI_API_KEY'];\nif (!apiKey) {\n  throw new Error('The AZURE_OPENAI_API_KEY environment variable is missing or empty.');\n}\n\nconst openai = new OpenAI({\n  apiKey,\n  baseURL: `https://${resource}.openai.azure.com/openai/deployments/${model}`,\n  defaultQuery: { 'api-version': apiVersion },\n  defaultHeaders: { 'api-key': apiKey },\n});\n\nasync function chatCompletion() {\n  const stream = await openai.beta.chat.completions.stream({\n    model: 'gpt-3.5-turbo',\n    messages: [{ role: 'user', content: 'Say this is a test' }],\n    stream: true,\n  });\n\n  stream.on('content', (delta, snapshot) => {\n    process.stdout.write(delta);\n  });\n\n  for await (const chunk of stream) {\n    process.stdout.write(chunk.choices[0]?.delta?.content || '');\n  }\n\n  const chatCompletion = await stream.finalChatCompletion();\n  console.log(chatCompletion); // {id: \"\u2026\", choices: [\u2026], \u2026}\n}\nchatCompletion()\n"))))),(0,a.kt)("h2",{id:"embedding"},"Embedding"),(0,a.kt)("table",null,(0,a.kt)("tr",null,(0,a.kt)("td",null," Engine ")," ",(0,a.kt)("td",null," Embedding ")),(0,a.kt)("tr",null,(0,a.kt)("td",null," Nitro "),(0,a.kt)("td",null,(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-typescript"},"import OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: '', // defaults to process.env[\"OPENAI_API_KEY\"]\n  baseURL: \"http://localhost:3928/v1/\" // https://api.openai.com/v1\n});\n\nasync function embedding() {\n  const embedding = await openai.embeddings.create({input: 'Hello How are you?', model: 'text-embedding-ada-002'});\n  console.log(embedding); // {object: \"list\", data: [\u2026], \u2026}\n}\n\nchatCompletion();\n")))),(0,a.kt)("tr",null,(0,a.kt)("td",null," OAI "),(0,a.kt)("td",null,(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-typescript"},"import OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: '', // defaults to process.env[\"OPENAI_API_KEY\"]\n});\n\nasync function embedding() {\n  const embedding = await openai.embeddings.create({input: 'Hello How are you?', model: 'text-embedding-ada-002'});\n  console.log(embedding); // {object: \"list\", data: [\u2026], \u2026}\n}\n\nchatCompletion();\n")))),(0,a.kt)("tr",null,(0,a.kt)("td",null," Azure OAI "),(0,a.kt)("td",null,(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-typescript"},"import OpenAI from 'openai';\n// The name of your Azure OpenAI Resource.\n// https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\nconst resource = '<your resource name>';\n\n// Corresponds to your Model deployment within your OpenAI resource, e.g. my-gpt35-16k-deployment\n// Navigate to the Azure OpenAI Studio to deploy a model.\nconst model = '<your model>';\n\n// https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\nconst apiVersion = '2023-06-01-preview';\n\nconst apiKey = process.env['AZURE_OPENAI_API_KEY'];\nif (!apiKey) {\n  throw new Error('The AZURE_OPENAI_API_KEY environment variable is missing or empty.');\n}\n\nconst openai = new OpenAI({\n  apiKey,\n  baseURL: `https://${resource}.openai.azure.com/openai/deployments/${model}`,\n  defaultQuery: { 'api-version': apiVersion },\n  defaultHeaders: { 'api-key': apiKey },\n});\n\nasync function embedding() {\n  const embedding = await openai.embeddings.create({input: 'Hello How are you?', model: 'text-embedding-ada-002'});\n  console.log(embedding); // {object: \"list\", data: [\u2026], \u2026}\n}\n\nchatCompletion();\n"))))),(0,a.kt)("h2",{id:"audio"},"Audio"),(0,a.kt)("p",null,"Coming soon"),(0,a.kt)("h2",{id:"how-to-reproduce"},"How to reproduce"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Step 1: Dependencies installation")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"npm install --save openai typescript\n# or\nyarn add openai\n")),(0,a.kt)("ol",{start:2},(0,a.kt)("li",{parentName:"ol"},"Step 2: Fill ",(0,a.kt)("inlineCode",{parentName:"li"},"tsconfig.json"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "compilerOptions": {\n    "moduleResolution": "node",\n    "sourceMap": true,\n    "outDir": "dist",\n    "target": "es2020",\n    "lib": ["es2020"],\n    "module": "commonjs",\n  },\n  "lib": ["es2015"]\n}\n')),(0,a.kt)("ol",{start:3},(0,a.kt)("li",{parentName:"ol"},"Step 3: Fill ",(0,a.kt)("inlineCode",{parentName:"li"},"index.ts")," file with code"),(0,a.kt)("li",{parentName:"ol"},"Step 4: Build with ",(0,a.kt)("inlineCode",{parentName:"li"},"npx tsc")),(0,a.kt)("li",{parentName:"ol"},"Step 5: Run the code with ",(0,a.kt)("inlineCode",{parentName:"li"},"node dist/index.js")),(0,a.kt)("li",{parentName:"ol"},"Step 6: Enjoy!")))}u.isMDXComponent=!0}}]);